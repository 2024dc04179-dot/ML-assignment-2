{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ML Assignment 2 - Model Training\n",
        "\n",
        "Train all 6 classification models and save them along with evaluation metrics.\n",
        "\n",
        "**Author:** Abhishek Anand (2024DC04179)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, roc_auc_score, precision_score, \n",
        "    recall_score, f1_score, matthews_corrcoef, confusion_matrix\n",
        ")\n",
        "import joblib\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Setup and Load Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create model directory if it doesn't exist\n",
        "script_dir = os.path.dirname(os.path.abspath(''))\n",
        "project_root = os.path.dirname(script_dir) if 'model' in script_dir else script_dir\n",
        "saved_models_dir = os.path.join(project_root, 'saved_models')\n",
        "os.makedirs(saved_models_dir, exist_ok=True)\n",
        "\n",
        "print(f\"Project root: {project_root}\")\n",
        "print(f\"Saved models directory: {saved_models_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "possible_paths = [\n",
        "    'data/Student_performance_data.csv',\n",
        "    '../data/Student_performance_data.csv',\n",
        "    os.path.join(project_root, 'data', 'Student_performance_data.csv'),\n",
        "    os.path.join(project_root, 'data', 'Student_Performance_data.csv')\n",
        "]\n",
        "\n",
        "df = None\n",
        "for path in possible_paths:\n",
        "    if os.path.exists(path):\n",
        "        df = pd.read_csv(path)\n",
        "        print(f\"Dataset loaded from: {path}\")\n",
        "        break\n",
        "\n",
        "if df is None:\n",
        "    raise FileNotFoundError(f\"Dataset not found. Tried paths: {possible_paths}\")\n",
        "\n",
        "print(f\"\\nDataset shape: {df.shape}\")\n",
        "print(f\"Columns: {list(df.columns)}\")\n",
        "print(f\"\\nFirst few rows:\")\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Separate features and target\n",
        "X = df.drop('GradeClass', axis=1)\n",
        "y = df['GradeClass']\n",
        "\n",
        "# Check for categorical features\n",
        "categorical_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
        "\n",
        "if categorical_cols:\n",
        "    print(f\"Encoding categorical features: {categorical_cols}\")\n",
        "    for col in categorical_cols:\n",
        "        le = LabelEncoder()\n",
        "        X[col] = le.fit_transform(X[col].astype(str))\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training set: {X_train.shape[0]} samples\")\n",
        "print(f\"Test set: {X_test.shape[0]} samples\")\n",
        "print(f\"Features: {X_train.shape[1]}\")\n",
        "print(f\"Target classes: {sorted(y.unique())}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale features (important for Logistic Regression, KNN, and Naive Bayes)\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Save scaler for later use\n",
        "scaler_path = os.path.join(saved_models_dir, 'scaler.pkl')\n",
        "joblib.dump(scaler, scaler_path)\n",
        "print(f\"Scaler saved to {scaler_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Define Metrics Calculation Function\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculate_metrics(y_true, y_pred, y_pred_proba):\n",
        "    \"\"\"Calculate all evaluation metrics for multiclass classification\"\"\"\n",
        "    if y_pred_proba.ndim == 1:\n",
        "        y_pred_proba = np.column_stack([1 - y_pred_proba, y_pred_proba])\n",
        "    \n",
        "    metrics = {\n",
        "        'accuracy': accuracy_score(y_true, y_pred),\n",
        "        'auc': roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average='macro'),\n",
        "        'precision': precision_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'recall': recall_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'f1': f1_score(y_true, y_pred, average='macro', zero_division=0),\n",
        "        'mcc': matthews_corrcoef(y_true, y_pred)\n",
        "    }\n",
        "    return metrics\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Train Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Logistic Regression...\")\n",
        "lr_model = LogisticRegression(random_state=42, max_iter=1000, multi_class='ovr')\n",
        "lr_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_lr = lr_model.predict(X_test_scaled)\n",
        "y_pred_proba_lr = lr_model.predict_proba(X_test_scaled)\n",
        "\n",
        "lr_metrics = calculate_metrics(y_test, y_pred_lr, y_pred_proba_lr)\n",
        "print(f\"Accuracy: {lr_metrics['accuracy']:.4f}\")\n",
        "print(f\"AUC: {lr_metrics['auc']:.4f}\")\n",
        "\n",
        "joblib.dump(lr_model, os.path.join(saved_models_dir, 'logistic_regression.pkl'))\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Train Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Decision Tree...\")\n",
        "dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)\n",
        "dt_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_dt = dt_model.predict(X_test)\n",
        "y_pred_proba_dt = dt_model.predict_proba(X_test)\n",
        "\n",
        "dt_metrics = calculate_metrics(y_test, y_pred_dt, y_pred_proba_dt)\n",
        "print(f\"Accuracy: {dt_metrics['accuracy']:.4f}\")\n",
        "print(f\"AUC: {dt_metrics['auc']:.4f}\")\n",
        "\n",
        "joblib.dump(dt_model, os.path.join(saved_models_dir, 'decision_tree.pkl'))\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Train K-Nearest Neighbors\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training KNN...\")\n",
        "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
        "knn_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_knn = knn_model.predict(X_test_scaled)\n",
        "y_pred_proba_knn = knn_model.predict_proba(X_test_scaled)\n",
        "\n",
        "knn_metrics = calculate_metrics(y_test, y_pred_knn, y_pred_proba_knn)\n",
        "print(f\"Accuracy: {knn_metrics['accuracy']:.4f}\")\n",
        "print(f\"AUC: {knn_metrics['auc']:.4f}\")\n",
        "\n",
        "joblib.dump(knn_model, os.path.join(saved_models_dir, 'knn.pkl'))\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Train Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Naive Bayes...\")\n",
        "nb_model = GaussianNB()\n",
        "nb_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_nb = nb_model.predict(X_test_scaled)\n",
        "y_pred_proba_nb = nb_model.predict_proba(X_test_scaled)\n",
        "\n",
        "nb_metrics = calculate_metrics(y_test, y_pred_nb, y_pred_proba_nb)\n",
        "print(f\"Accuracy: {nb_metrics['accuracy']:.4f}\")\n",
        "print(f\"AUC: {nb_metrics['auc']:.4f}\")\n",
        "\n",
        "joblib.dump(nb_model, os.path.join(saved_models_dir, 'naive_bayes.pkl'))\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9. Train Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training Random Forest...\")\n",
        "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "y_pred_proba_rf = rf_model.predict_proba(X_test)\n",
        "\n",
        "rf_metrics = calculate_metrics(y_test, y_pred_rf, y_pred_proba_rf)\n",
        "print(f\"Accuracy: {rf_metrics['accuracy']:.4f}\")\n",
        "print(f\"AUC: {rf_metrics['auc']:.4f}\")\n",
        "\n",
        "joblib.dump(rf_model, os.path.join(saved_models_dir, 'random_forest.pkl'))\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10. Train XGBoost\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"Training XGBoost...\")\n",
        "xgb_model = XGBClassifier(random_state=42, eval_metric='logloss')\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "y_pred_proba_xgb = xgb_model.predict_proba(X_test)\n",
        "\n",
        "xgb_metrics = calculate_metrics(y_test, y_pred_xgb, y_pred_proba_xgb)\n",
        "print(f\"Accuracy: {xgb_metrics['accuracy']:.4f}\")\n",
        "print(f\"AUC: {xgb_metrics['auc']:.4f}\")\n",
        "\n",
        "joblib.dump(xgb_model, os.path.join(saved_models_dir, 'xgboost.pkl'))\n",
        "print(\"Model saved!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Results Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compile all results\n",
        "results = {\n",
        "    'Logistic Regression': lr_metrics,\n",
        "    'Decision Tree': dt_metrics,\n",
        "    'kNN': knn_metrics,\n",
        "    'Naive Bayes': nb_metrics,\n",
        "    'Random Forest': rf_metrics,\n",
        "    'XGBoost': xgb_metrics\n",
        "}\n",
        "\n",
        "results_df = pd.DataFrame(results).T\n",
        "results_df.columns = ['Accuracy', 'AUC', 'Precision', 'Recall', 'F1', 'MCC']\n",
        "results_df.index.name = 'Model'\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"MODEL PERFORMANCE SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(results_df.round(4))\n",
        "\n",
        "# Find best model\n",
        "best_model = results_df['Accuracy'].idxmax()\n",
        "best_accuracy = results_df['Accuracy'].max()\n",
        "print(f\"\\nBest Model: {best_model} (Accuracy: {best_accuracy:.4f})\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 12. Save Results to Excel\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save results to Excel\n",
        "results_path = os.path.join(project_root, 'ML_Assignment_2_Results.xlsx')\n",
        "results_df.to_excel(results_path, index=True)\n",
        "print(f\"Results saved to {results_path}\")\n",
        "print(\"\\nTraining complete! All models saved to saved_models/ directory.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}